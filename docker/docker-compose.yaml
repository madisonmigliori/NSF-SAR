
services:
  rag:
    image: 'madisonmigliori444/rag'
    ports: 
      - '8080:8080'
    depends_on:
      chroma:
        condition: service_healthy
      ollama:
        condition: service_healthy
    restart: on-failure
    environment:
      SPRING_AI_VECTORSTORE_CHROMA_CLIENT_HOST: localhost
      SPRING_AI_VECTORSTORE_CHROMA_CLIENT_PORT: 8000
  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    ports:
      - '8000:8000'
    volumes:
      - chroma_data:/chroma/.chroma
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8000/api/v2/healthcheck | grep -q '\"is_executor_ready\": true'"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  ollama:
    image: ollama/ollama:latest
    ports:
      - '11434:11434'
    command: ["serve"]
    volumes:
      - ~/.ollama:/root/.ollama
    environment:
      OLLAMA_MODELS: /root/.ollama/models
      OLLAMA_RUN_MODELS: llama3,nomic-embed-text
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:11434/api/tags | grep -q 'llama3' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s


volumes:
  chroma_data:
  ollama_data:
