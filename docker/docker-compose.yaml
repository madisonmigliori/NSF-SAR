
services:
  rag:
    image: 'madisonmigliori444/rag'
    ports: 
      - '8080:8080'
    # depends_on:
    #   chroma:
    #     condition: service_healthy
    #   ollama:
    #     condition: service_healthy
    restart: on-failure
    environment:
      SPRING_AI_VECTORSTORE_CHROMA_CLIENT_HOST: localhost
      SPRING_AI_VECTORSTORE_CHROMA_CLIENT_PORT: 8000
  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    ports:
      - '8000:8000'
    volumes:
      - chroma_data:/chroma/.chroma
    # healthcheck:
    #   test: ["CMD-SHELL", "curl -sf http://localhost:8000/docs"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 5
    #   start_period: 10s
   
  ollama:
    image: ollama/ollama:latest
    ports:
      - '11434:11434'
    command: ["serve"]
    volumes:
      - ~/.ollama:/root/.ollama
    environment:
      OLLAMA_MODELS: /root/.ollama/models
      OLLAMA_RUN_MODELS: llama3,nomic-embed-text
    # healthcheck:
    #   test: ["CMD-SHELL", "curl -sf http://localhost:11434 || exit 1"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 10
    #   start_period: 30s
   


volumes:
  chroma_data:
  ollama_data:
