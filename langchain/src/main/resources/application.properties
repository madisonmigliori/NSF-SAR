spring.application.name=langchain

ollama.model.name=llama3

app.ollama-endpoint=http://localhost:11434
app.chroma-endpoint=http://localhost:8000

# langchain4j.ollama.chat-model.base-url:http://localhost:11434
langchain4j.ollama.chat-model.model-name=llama3.2
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true
langchain4j.ollama.chat-model.temperature=0.8
langchain4j.ollama.chat-model.timeout=PT60S

spring.ai.ollama.chat.options.model=llama3.2
spring.ai.ollama.chat.enabled=true
spring.ai.ollama.embedding.options.model=nomic-embed-text
spring.ai.ollama.embedding.enabled=true

spring.ai.vectorstore.chroma.initialize-schema=true
spring.ai.vectorstore.chroma.collection-name=collection

logging.level.org.springframework=ERROR
logging.level.dev.langchain4j=DEBUG
logging.level.ai.djl=DEBUG

spring.datasource.driverClassName=org.h2.Driver
spring.datasource.url=jdbc:h2:mem:hair_booking
spring.h2.console.enabled=true
spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
spring.jpa.hibernate.ddl-auto=create
spring.jpa.show-sql=false